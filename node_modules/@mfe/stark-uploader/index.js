const fs = require('fs');
const flatten = require('lodash.flatten');

const {
  resolve,
  relative
} = require('path');
const axios = require('axios');
const FormData = require('form-data');
const micromatch = require('micromatch');
const filesize = require('filesize');
const promiseLimit = require('promise-limit');
const { validateFileByUrl } = require('@mfe/stark-validator');
const { zipFiles, zipFilesIntoChunks } = require('./lib/zip');
const { batchFilesByCount } = require('./lib/misc');
const {
  findFileCdnUrl,
  mergeStaticUploadResults,
  validateMassiveStaticFile
} = require('./lib/misc');

const DEFAULT_STATIC_UPLOAD_URL = 'http://stark.sankuai.com/shell/upload';
const DEFAULT_DYNAMIC_UPLOAD_URL = 'http://stark.sankuai.com/shell/upload-dynamic';


const UPDATE_ZIP_NAME = 'update.zip';
const MAX_ZIP_LENGTH = 20 * 1024 * 1024;
const MAX_FILE_COUNT = 50;

const VALIDATE_CONCURRENT_COUNT = 5;
const VALIDATE_INTERVAL = 2000;

function sleep() {
  return new Promise((resolve) => setTimeout(resolve, VALIDATE_INTERVAL));
}

function inputGlobToGlobList(inputGlobString) {
  return inputGlobString.split(' ');
}

function doUpload(fileBuffer, { projectName, secretKey, uploadUrl , verbose}) {
  const url = uploadUrl || DEFAULT_STATIC_UPLOAD_URL;
  const form = new FormData();
  form.append('appkey', projectName);
  if (secretKey) {
    form.append('secretkey', secretKey);
  }
  form.append('file', fileBuffer, UPDATE_ZIP_NAME);

  console.log(`Uploading to "${url}", compressed size ${filesize(fileBuffer.byteLength)}`);
  return axios.post(url, form, {
    headers: form.getHeaders(),
    maxContentLength: MAX_ZIP_LENGTH,
    validateStatus: status => status === 200
  }).then(response => {
    if(verbose) {
      console.log('Upload response', response);
    }
    return response.data;
  });
}

function validateStaticUploads(files, uploadResult) {
  console.log("Start to validate uploaded static content...");
  const responseFileCount = uploadResult.cdnpath.length;
  const fileCount = files.length;
  if (responseFileCount > fileCount) {
    return Promise.reject(new Error(`Response upload file count ${responseFileCount} doesn't match ${fileCount}`));
  }
  const limit = promiseLimit(VALIDATE_CONCURRENT_COUNT);
  const validatingPromiseArray = files.map(file => {
    const url = findFileCdnUrl(file.fileName, uploadResult);
    return limit(() => {
      return sleep().then(() => {
        console.log(Date.now().toString(), "Validate", url);
        return validateFileByUrl(url, file.filePath);
      });
    }).catch(err => {
      if (err.toString().indexOf("ETIMEDOUT")) {
        console.log("Url", url, "timeout, skip.");
        return;
      }
      if (err.toString().indexOf('ECONNRESET')) {
        console.log('Url', url, 'rejected, skip.');
        return;
      }
      throw err;
    });
  });

  return Promise.all(validatingPromiseArray).then(
    () => {
      console.log("Validate CDN content success.");
      return uploadResult;
    },
    err => {
      console.error("Validate content of CDN file error");
      throw err;
    }
  );
}

function uploadStaticFiles(files, projectName, uploadUrl, skipValidation, secretKey, verbose) {
  if (!files.length) {
    return Promise.resolve([]);
  }
  return zipFiles(files)
    .then(resultBuffer => {
      return doUpload(resultBuffer, { projectName, secretKey, uploadUrl, verbose});
    })
    .then(uploadResult => {
      if (skipValidation) {
        console.log("Validation of static content skipped...");
        return uploadResult;
      }
      return validateStaticUploads(files, uploadResult);
    });
}

function uploadMassiveStaticFiles(files, projectName, uploadUrl, skipValidation, secretKey) {
  if (!files.length) {
    return Promise.resolve({
      code: 400,
      cdnpath: [],
      failedFiles: [],
      allFilesUploadSuccess: false
    });
  }
  if (files.length > MAX_FILE_COUNT){
    const batchFiles = batchFilesByCount(files, MAX_FILE_COUNT);
    console.log('batchFiles',batchFiles);
    return Promise.all(
      batchFiles.map(batchItem => zipFilesIntoChunks(batchItem, MAX_ZIP_LENGTH).then(
        resultBufferArray => Promise.all(
          resultBufferArray.map(resultBuffer => doUpload(resultBuffer, { projectName, secretKey, uploadUrl }))
        )
      ))
    ).then(uploadResultArray => {
        uploadResultArray = flatten(uploadResultArray);
        return mergeStaticUploadResults(uploadResultArray);
      })
      .then( async (mergedUploadResult) => {
        const { failedFiles, allFilesUploadSuccess } = await validateMassiveStaticFile(files, mergedUploadResult);
        return {
          code: mergedUploadResult.code,
          cdnpath: mergedUploadResult.cdnpath,
          failedFiles: failedFiles,
          allFilesUploadSuccess: allFilesUploadSuccess
        };
      });
  }
  return zipFilesIntoChunks(files, MAX_ZIP_LENGTH)
    .then(resultBufferArray => {
      return Promise.all(
        resultBufferArray.map((resultBuffer) => {
          return doUpload(resultBuffer, { projectName, secretKey, uploadUrl })
        })
      )
      .then(uploadResultArray => {
        console.log("Validation of static content ...");
        return mergeStaticUploadResults(uploadResultArray);
      }).then(async (mergedUploadResult) => {
        const { failedFiles, allFilesUploadSuccess } = await validateMassiveStaticFile(files, mergedUploadResult);
        return {
          code: mergedUploadResult.code,
          cdnpath: mergedUploadResult.cdnpath,
          failedFiles: failedFiles,
          allFilesUploadSuccess: allFilesUploadSuccess
        };
      });
    })
    .catch(err => {
      console.error(err);
      return {
        code: 400,
        cdnpath: [],
        failedFiles: files,
        allFilesUploadSuccess: false
      };
    });
}
function uploadMassiveStaticFilesFromCmd(files, projectName, uploadUrl, skipValidation, secretKey, verbose) {
  if (!files.length) {
    return Promise.resolve([]);
  }
  if (files.length > MAX_FILE_COUNT) {
    const batchFiles = batchFilesByCount(files, MAX_FILE_COUNT);
    console.log('batchFiles',batchFiles)
    return Promise.all(
      batchFiles.map(batchItem => zipFilesIntoChunks(batchItem, MAX_ZIP_LENGTH, MAX_FILE_COUNT).then(
        resultBufferArray => Promise.all(
          resultBufferArray.map(resultBuffer => doUpload(resultBuffer, { projectName, secretKey, uploadUrl, verbose}))
        )
      ))
    ).then(uploadResultArray => {
        uploadResultArray = flatten(uploadResultArray);
        return mergeStaticUploadResults(uploadResultArray);
      })
      .then(mergedUploadResult => {
        if (skipValidation) {
          console.log('Validation of static content skipped...');
          return mergedUploadResult;
        }
        console.log('Validation of static content ...');
        return validateStaticUploads(files, mergedUploadResult);
      });
  }
  return zipFilesIntoChunks(files, MAX_ZIP_LENGTH, MAX_FILE_COUNT)
    .then(resultBufferArray => {
      return Promise.all(
        resultBufferArray.map((resultBuffer) => {
          return doUpload(resultBuffer, { projectName, secretKey, uploadUrl, verbose })
        })
      )
      .then(uploadResultArray => {
        return mergeStaticUploadResults(uploadResultArray);
      }).then((mergedUploadResult) => {
        if (skipValidation) {
          console.log("Validation of static content skipped...");
          return mergedUploadResult;
        }
        console.log("Validation of static content ...");
        return validateStaticUploads(files, mergedUploadResult);
      });
    });
  }
function filterGlobList(fileList, globList) {
  return micromatch(fileList.map(file => file.fileName), globList).map(fileName => {
    const file = fileList.find((file) => file.fileName === fileName);
    if (!file) {
      throw new Error('Cannot find file back from micromatch');
    }
    return file;
  });
}

function assembleDirFiles(dirBase, dirPath) {
  const collectedFiles = [];
  const entries = fs.readdirSync(dirPath);
  for (let index = 0; index < entries.length; index++) {
    const entry = entries[index];
    const entryPath = resolve(dirPath, entry);

    const stat = fs.statSync(entryPath);

    if (stat.isFile()) {
      collectedFiles.push({
        filePath: entryPath,
        fileName: relative(dirBase, entryPath),
        fileSize: stat.size
      });
      continue;
    }

    if (stat.isDirectory()) {
      const subFiles = assembleDirFiles(dirBase, entryPath);
      collectedFiles.push(...subFiles);
      continue;
    }
  }
  return collectedFiles;
}

function outputUploadedFiles(staticFiles, dynamicFiles) {
  console.log('\nStatic files to upload:');
  console.log(staticFiles.map(file => file.fileName).join('\n'));
  console.log('\nDynamic files to upload:');
  console.log(dynamicFiles.map(file => file.fileName).join('\n'));
}

function gatherFiles(basePath, staticGlobs, dynamicGlobs) {
  const files = assembleDirFiles(basePath, basePath);
  const staticFiles = filterGlobList(files, staticGlobs);
  const dynamicFiles = filterGlobList(files, dynamicGlobs);
  return { staticFiles, dynamicFiles };
}

function uploadDynamicFiles(dynamicFiles, projectName, uploadDynamicUrl, secretKey) {
  if (!dynamicFiles.length) {
    return Promise.resolve([]);
  }
  // TODO: validate dynamic files after upload.
  return zipFiles(dynamicFiles).then((resultBuffer) => {
    return doUpload(resultBuffer, {
      projectName,
      secretKey,
      uploadUrl: uploadDynamicUrl || DEFAULT_DYNAMIC_UPLOAD_URL
    });
  });
}

function uploadStaticAndDynamicDryRun(dirPath,
  {
    staticFileInputGlobs,
    dynamicFileInputGlobs,
  }) {
  const staticGlobs = inputGlobToGlobList(staticFileInputGlobs);
  const dynamicGlobs = inputGlobToGlobList(dynamicFileInputGlobs);
  const {
    staticFiles,
    dynamicFiles
  } = gatherFiles(dirPath, staticGlobs, dynamicGlobs);

  outputUploadedFiles(staticFiles, dynamicFiles);

  return;
}

function uploadStaticAndDynamic(
  dirPath,
  projectName,
  {
    staticUploadUrl,
    staticFileInputGlobs,
    dynamicUploadUrl,
    dynamicFileInputGlobs,
    skipValidation,
    secretKey,
    autoSplit,
    skipFilter,
    verbose
  }
) {
  const staticGlobs = inputGlobToGlobList(staticFileInputGlobs);
  const dynamicGlobs = inputGlobToGlobList(dynamicFileInputGlobs);
  const { staticFiles, dynamicFiles } = gatherFiles(
    dirPath,
    staticGlobs,
    dynamicGlobs
  );
  return genFinalStaticFiles(staticFiles, projectName, staticUploadUrl, skipFilter).then((finalStaticFiles)=>{
    outputUploadedFiles(finalStaticFiles, dynamicFiles);
    let staticFileResult = null;
    const uploadStaticFun = autoSplit ? uploadMassiveStaticFilesFromCmd : uploadStaticFiles;
    // NOTE: 首先需要保证静态文件已经上传，其次再上传使用静态文件的动态的文件
    return uploadStaticFun(finalStaticFiles, projectName, staticUploadUrl, skipValidation, secretKey, verbose)
      .then(result => {
        staticFileResult = result;
        return uploadDynamicFiles(dynamicFiles, projectName, dynamicUploadUrl, secretKey);
      })
      .then(dynamicFileResult => {
        return [staticFileResult, dynamicFileResult];
      });
    
  })
}
function genFinalStaticFiles (files, appkey, uploadUrl, skipFilter){
  if(skipFilter) {
    return Promise.resolve(files);
  }
  const url = uploadUrl || DEFAULT_STATIC_UPLOAD_URL;
  const pathIndex = url.indexOf('/shell/upload');
  const filterUrl = `${url.substring(0, pathIndex)}/shell/filterFiles`;
  return axios.post(filterUrl, {
    files,
    appkey
  }).then((filterRes)=>{
    console.log('文件过滤结果',filterRes.data);
    if(filterRes.data.code !== 200){
      throw new Error(filterRes.data.msg)
    }else {
      return filterRes.data.result;
    }
  })
}
module.exports = {
  // export for test only
  _assembleDirFiles: assembleDirFiles,
  _inputGlobToGlobList: inputGlobToGlobList,
  _filterGlobList: filterGlobList,

  DEFAULT_STATIC_UPLOAD_URL,
  DEFAULT_DYNAMIC_UPLOAD_URL,

  validateStaticUploads,

  gatherFiles,
  uploadStaticFiles,
  uploadMassiveStaticFiles,
  uploadMassiveStaticFilesFromCmd,
  uploadDynamicFiles,
  uploadStaticAndDynamic,
  uploadStaticAndDynamicDryRun,
};